{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/petpoint/blob/main/Copy_of_PetpointWithGeneralConver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jika Anda menggunakan Google Colab, pastikan untuk meng-clone repository terlebih dahulu\n",
        "!git clone https://github.com/bryanbayup/petpoint\n",
        "\n",
        "# Pastikan directory kerja Anda berada di tempat yang benar\n",
        "import os\n",
        "os.chdir('/content/petpoint')"
      ],
      "metadata": {
        "id": "qGzxvwmNAtcW",
        "outputId": "37d32696-cc62-4083-80b7-d1576fc2f77d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'petpoint'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 51 (delta 8), reused 28 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (51/51), 81.82 KiB | 644.00 KiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import random\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# Pastikan Anda telah menginstall library yang diperlukan\n",
        "!pip install stanza transformers sentencepiece\n",
        "\n",
        "import stanza\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
      ],
      "metadata": {
        "id": "poMoEOOqAw_V",
        "outputId": "d3fa1674-c859-40df-a680-4ca086a9375b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.9.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stanza) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from stanza) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stanza) (4.66.6)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from stanza) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->stanza) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.9.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji, stanza\n",
            "Successfully installed emoji-2.14.0 stanza-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List untuk menyimpan pasangan percakapan\n",
        "conversation_pairs = []\n",
        "\n",
        "# Fungsi untuk mengekstrak pasangan percakapan dari intents\n",
        "def extract_conversation_pairs(intents):\n",
        "    pairs = []\n",
        "    for intent in intents:\n",
        "        for utterance in intent['utterances']:\n",
        "            for answer in intent['answers']:\n",
        "                pairs.append((utterance, answer))\n",
        "    return pairs\n",
        "\n",
        "# Load semua JSON files dari corpus/id/\n",
        "intents = []\n",
        "for file in glob.glob('corpus/id/*.json'):\n",
        "    with open(file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "        intents.extend(data)\n",
        "\n",
        "# Load domain-specific data\n",
        "with open('kucing_anjing/kucing_anjing.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "    intents.extend(data)\n",
        "\n",
        "# Ekstrak pasangan percakapan\n",
        "conversation_pairs.extend(extract_conversation_pairs(intents))\n",
        "\n",
        "# Membuat DataFrame\n",
        "df = pd.DataFrame(conversation_pairs, columns=['input', 'response'])"
      ],
      "metadata": {
        "id": "MsI4FpsIA3Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load normalization dictionary\n",
        "normalization_dict = {}\n",
        "with open('normalization/normalization.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        # Check if the line contains the delimiter before splitting\n",
        "        if '\\t' in line:\n",
        "            slang, normal = line.strip().split('\\t')\n",
        "            normalization_dict[slang] = normal\n",
        "        else:\n",
        "            print(f\"Warning: Skipping line '{line.strip()}', no tab delimiter found.\")\n",
        "\n",
        "# Function to normalize text\n",
        "def normalize_text(text):\n",
        "    words = text.split()\n",
        "    normalized_words = [normalization_dict.get(word, word) for word in words]\n",
        "    return ' '.join(normalized_words)\n",
        "\n",
        "# Load stopwords\n",
        "with open('normalization/stopword.txt', 'r', encoding='utf-8') as f:\n",
        "    stopwords = set(f.read().splitlines())\n",
        "\n",
        "# Function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in stopwords]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Initialize the Indonesian pipeline\n",
        "stanza.download('id')  # Jika sudah pernah di-download, bisa dilewatkan\n",
        "nlp = stanza.Pipeline('id', processors='tokenize,pos,lemma', use_gpu=True)\n",
        "\n",
        "def tokenize_and_lemmatize(text):\n",
        "    doc = nlp(text)\n",
        "    lemmas = [word.lemma for sentence in doc.sentences for word in sentence.words]\n",
        "    return ' '.join(lemmas)\n",
        "\n",
        "# Function for preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Normalisasi\n",
        "    text = normalize_text(text.lower())\n",
        "    # Hapus stopwords\n",
        "    text = remove_stopwords(text)\n",
        "    # Tokenisasi dan Lematisasi\n",
        "    text = tokenize_and_lemmatize(text)\n",
        "    return text\n",
        "\n",
        "# Terapkan preprocessing\n",
        "df['input'] = df['input'].apply(preprocess_text)\n",
        "df['response'] = df['response'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "j490iFMmA8ff",
        "outputId": "516b04e9-a3cc-41be-b140-6c12a0aa185c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842,
          "referenced_widgets": [
            "a12607554eea41c490e1f5ced90e155f",
            "4c19e77b5e384bcf8a356bcabaf85674",
            "14f373296b0f4b1e95d0377ab1cc4c93",
            "44ec5659fe6248c0ac0f9159432d28ba",
            "4acc871b566743ca9512ecd93477d610",
            "c6914613b3764e37a122455c257c7421",
            "0281dcac88584cc9ad10fa8ab6a5c96c",
            "41f15e9899cc4ca390baefae14bfc0b0",
            "0ce05ff926da4626926bb2c6e89bcccd",
            "f1af3c38d93f445c83c0bf926d4f2914",
            "4c38740fe29f48399abdb052e34a817f",
            "4829483efe8b49488a904e632f5ac32b",
            "6198ca1a06a54d009f4bacc7e4be598d",
            "02f2e974c93e40f680d3221295edd13b",
            "c4cfdd33300948c082fa677a7db63c56",
            "35cf77d5b258472a9769013580e6349a",
            "d8615ebee419435c8699e3e1f53773e2",
            "8d33f766d4834d66a0dd7f54119f1271",
            "57a3c3fb203046cca87d9053e12baef1",
            "a2c52ccdfb504ed996f893fa39242d5e",
            "ccb056953e944d3c9ae14584cb2800f6",
            "4579de5039e647eb989ca5ebdcee1760",
            "0a5b58f5734f4e099dd7b25b2ba44912",
            "452bd189e9c04d52b0893360e72858d0",
            "708110d4718c4fcf91be57fc77e4919b",
            "299657f864d44ebba3046218a0a12c06",
            "54d00c244f0842abacf252f3b8f8c94c",
            "1f8c9fa4efe24700951d5d00b7d9856b",
            "1aa896e594754a89b117cce9734ed80c",
            "b758b259db694a1db717777ed8d2e89a",
            "3b60d4a4e16a4c4da241dce0a6677f24",
            "cc24971afadf43b89e3d573d5f2701ca",
            "8b2af3c4034a46689f689edff5d551f0"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping line 'kuy ayo', no tab delimiter found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a12607554eea41c490e1f5ced90e155f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "INFO:stanza:Downloading default packages for language: id (Indonesian) ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.9.0/models/default.zip:   0%|          | 0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4829483efe8b49488a904e632f5ac32b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/id/default.zip\n",
            "INFO:stanza:Finished downloading models and saved to /root/stanza_resources\n",
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a5b58f5734f4e099dd7b25b2ba44912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Downloaded file to /root/stanza_resources/resources.json\n",
            "WARNING:stanza:Language id package default expects mwt, which has been added\n",
            "INFO:stanza:Loading these models for language: id (Indonesian):\n",
            "============================\n",
            "| Processor | Package      |\n",
            "----------------------------\n",
            "| tokenize  | gsd          |\n",
            "| mwt       | gsd          |\n",
            "| pos       | gsd_charlm   |\n",
            "| lemma     | gsd_nocharlm |\n",
            "============================\n",
            "\n",
            "INFO:stanza:Using device: cuda\n",
            "INFO:stanza:Loading: tokenize\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: mwt\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/mwt/trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: pos\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Loading: lemma\n",
            "/usr/local/lib/python3.10/dist-packages/stanza/models/lemma/trainer.py:239: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sentences, max_vocab_size=5000):\n",
        "    word_counts = Counter(itertools.chain(*[s.split() for s in sentences]))\n",
        "    most_common = word_counts.most_common(max_vocab_size)\n",
        "    idx2word = ['<PAD>', '<SOS>', '<EOS>', '<UNK>'] + [word for word, _ in most_common]\n",
        "    word2idx = {word: idx for idx, word in enumerate(idx2word)}\n",
        "    return word2idx, idx2word\n",
        "\n",
        "# Bangun vocabulary untuk input dan output\n",
        "input_word2idx, input_idx2word = build_vocab(df['input'])\n",
        "output_word2idx, output_idx2word = build_vocab(df['response'])\n",
        "\n",
        "def sentence_to_indices(sentence, word2idx):\n",
        "    indices = [word2idx.get(word, word2idx['<UNK>']) for word in sentence.split()]\n",
        "    return indices\n",
        "\n",
        "# Menambahkan indeks ke DataFrame\n",
        "df['input_indices'] = df['input'].apply(lambda x: sentence_to_indices(x, input_word2idx))\n",
        "df['response_indices'] = df['response'].apply(lambda x: [output_word2idx['<SOS>']] + sentence_to_indices(x, output_word2idx) + [output_word2idx['<EOS>']])"
      ],
      "metadata": {
        "id": "aXc3ZfghA_BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "M6r93ub7BT7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatDataset(Dataset):\n",
        "    def __init__(self, inputs, outputs):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.inputs[idx], dtype=torch.long), torch.tensor(self.outputs[idx], dtype=torch.long)\n",
        "\n",
        "# Training Dataset dan DataLoader\n",
        "train_dataset = ChatDataset(train_df['input_indices'].tolist(), train_df['response_indices'].tolist())\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: x)\n",
        "\n",
        "# Validation Dataset dan DataLoader\n",
        "val_dataset = ChatDataset(val_df['input_indices'].tolist(), val_df['response_indices'].tolist())\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: x)"
      ],
      "metadata": {
        "id": "bBVgXUNjBXRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embed_size, hidden_size, num_layers=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length]\n",
        "        embedding = self.embedding(x)\n",
        "        outputs, (hidden, cell) = self.lstm(embedding)\n",
        "        return hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embed_size, hidden_size, num_layers=1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "        # x: [batch_size]\n",
        "        x = x.unsqueeze(1)  # [batch_size, 1]\n",
        "        embedding = self.embedding(x)\n",
        "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "        predictions = self.fc(outputs.squeeze(1))\n",
        "        return predictions, hidden, cell\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, output_word2idx):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.output_word2idx = output_word2idx\n",
        "\n",
        "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = source.size(0)\n",
        "        target_len = target.size(1)\n",
        "        target_vocab_size = len(self.output_word2idx)\n",
        "\n",
        "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n",
        "        hidden, cell = self.encoder(source)\n",
        "\n",
        "        x = target[:, 0]\n",
        "\n",
        "        for t in range(1, target_len):\n",
        "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "            outputs[:, t] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            x = target[:, t] if random.random() < teacher_forcing_ratio else best_guess\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "L31Lq2sEBZ9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained FastText embeddings\n",
        "fasttext_model = api.load('fasttext-wiki-news-subwords-300')\n",
        "\n",
        "# Membuat embedding matrix\n",
        "embedding_dim = 300\n",
        "vocab_size = len(input_word2idx)\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, idx in input_word2idx.items():\n",
        "    try:\n",
        "        embedding_vector = fasttext_model[word]\n",
        "        embedding_matrix[idx] = embedding_vector\n",
        "    except KeyError:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim, ))\n",
        "\n",
        "# Memperbarui layer embedding pada Encoder\n",
        "encoder_net.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False)"
      ],
      "metadata": {
        "id": "R-oEty7cDOb3",
        "outputId": "824a5fad-bb5c-4793-d3f2-30bc377f0d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "input_size_encoder = len(input_word2idx)\n",
        "input_size_decoder = len(output_word2idx)\n",
        "output_size = len(output_word2idx)\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "learning_rate = 0.001\n",
        "num_epochs = 30\n",
        "\n",
        "encoder_net = Encoder(input_size_encoder, embed_size, hidden_size, num_layers).to(device)\n",
        "decoder_net = Decoder(output_size, embed_size, hidden_size, num_layers).to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_net, decoder_net, output_word2idx).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=output_word2idx['<PAD>'])"
      ],
      "metadata": {
        "id": "di7zKywkBcEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        # Ambil batch data\n",
        "        inputs, targets = zip(*batch)\n",
        "        inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=input_word2idx['<PAD>']).to(device)\n",
        "        targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=output_word2idx['<PAD>']).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs, targets)\n",
        "\n",
        "        # Reshape untuk menghitung loss\n",
        "        outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "        targets = targets[:, 1:].reshape(-1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "    # Evaluasi pada Validation Set\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(val_dataloader):\n",
        "            inputs, targets = zip(*batch)\n",
        "            inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=input_word2idx['<PAD>']).to(device)\n",
        "            targets = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=output_word2idx['<PAD>']).to(device)\n",
        "\n",
        "            outputs = model(inputs, targets, teacher_forcing_ratio=0)  # No teacher forcing during evaluation\n",
        "\n",
        "            outputs = outputs[:, 1:].reshape(-1, outputs.shape[2])\n",
        "            targets = targets[:, 1:].reshape(-1)\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "    print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')"
      ],
      "metadata": {
        "id": "timNIxvuBfHB",
        "outputId": "8987c47c-6eaf-45d9-e21d-849d4c8ba35f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30]\n",
            "Epoch 1, Training Loss: 4.9803\n",
            "Epoch 1, Validation Loss: 4.6864\n",
            "Epoch [2/30]\n",
            "Epoch 2, Training Loss: 4.3357\n",
            "Epoch 2, Validation Loss: 4.4400\n",
            "Epoch [3/30]\n",
            "Epoch 3, Training Loss: 3.9284\n",
            "Epoch 3, Validation Loss: 4.2024\n",
            "Epoch [4/30]\n",
            "Epoch 4, Training Loss: 3.5980\n",
            "Epoch 4, Validation Loss: 4.1366\n",
            "Epoch [5/30]\n",
            "Epoch 5, Training Loss: 3.2753\n",
            "Epoch 5, Validation Loss: 3.9849\n",
            "Epoch [6/30]\n",
            "Epoch 6, Training Loss: 2.8974\n",
            "Epoch 6, Validation Loss: 3.9328\n",
            "Epoch [7/30]\n",
            "Epoch 7, Training Loss: 2.6071\n",
            "Epoch 7, Validation Loss: 3.9728\n",
            "Epoch [8/30]\n",
            "Epoch 8, Training Loss: 2.4143\n",
            "Epoch 8, Validation Loss: 3.9303\n",
            "Epoch [9/30]\n",
            "Epoch 9, Training Loss: 1.9993\n",
            "Epoch 9, Validation Loss: 4.0028\n",
            "Epoch [10/30]\n",
            "Epoch 10, Training Loss: 1.6743\n",
            "Epoch 10, Validation Loss: 3.8787\n",
            "Epoch [11/30]\n",
            "Epoch 11, Training Loss: 1.3154\n",
            "Epoch 11, Validation Loss: 3.6530\n",
            "Epoch [12/30]\n",
            "Epoch 12, Training Loss: 1.2862\n",
            "Epoch 12, Validation Loss: 4.0287\n",
            "Epoch [13/30]\n",
            "Epoch 13, Training Loss: 0.9107\n",
            "Epoch 13, Validation Loss: 3.4927\n",
            "Epoch [14/30]\n",
            "Epoch 14, Training Loss: 0.9557\n",
            "Epoch 14, Validation Loss: 3.1215\n",
            "Epoch [15/30]\n",
            "Epoch 15, Training Loss: 0.8052\n",
            "Epoch 15, Validation Loss: 2.9539\n",
            "Epoch [16/30]\n",
            "Epoch 16, Training Loss: 0.6806\n",
            "Epoch 16, Validation Loss: 3.2752\n",
            "Epoch [17/30]\n",
            "Epoch 17, Training Loss: 0.6704\n",
            "Epoch 17, Validation Loss: 2.4918\n",
            "Epoch [18/30]\n",
            "Epoch 18, Training Loss: 0.7287\n",
            "Epoch 18, Validation Loss: 2.3790\n",
            "Epoch [19/30]\n",
            "Epoch 19, Training Loss: 0.5813\n",
            "Epoch 19, Validation Loss: 2.3965\n",
            "Epoch [20/30]\n",
            "Epoch 20, Training Loss: 0.6247\n",
            "Epoch 20, Validation Loss: 2.0601\n",
            "Epoch [21/30]\n",
            "Epoch 21, Training Loss: 0.4811\n",
            "Epoch 21, Validation Loss: 2.2102\n",
            "Epoch [22/30]\n",
            "Epoch 22, Training Loss: 0.5221\n",
            "Epoch 22, Validation Loss: 2.5500\n",
            "Epoch [23/30]\n",
            "Epoch 23, Training Loss: 0.5603\n",
            "Epoch 23, Validation Loss: 2.4344\n",
            "Epoch [24/30]\n",
            "Epoch 24, Training Loss: 0.4852\n",
            "Epoch 24, Validation Loss: 2.7524\n",
            "Epoch [25/30]\n",
            "Epoch 25, Training Loss: 0.4781\n",
            "Epoch 25, Validation Loss: 2.2150\n",
            "Epoch [26/30]\n",
            "Epoch 26, Training Loss: 0.3993\n",
            "Epoch 26, Validation Loss: 2.5773\n",
            "Epoch [27/30]\n",
            "Epoch 27, Training Loss: 0.4010\n",
            "Epoch 27, Validation Loss: 2.3921\n",
            "Epoch [28/30]\n",
            "Epoch 28, Training Loss: 0.4240\n",
            "Epoch 28, Validation Loss: 2.6814\n",
            "Epoch [29/30]\n",
            "Epoch 29, Training Loss: 0.3818\n",
            "Epoch 29, Validation Loss: 2.4768\n",
            "Epoch [30/30]\n",
            "Epoch 30, Training Loss: 0.4408\n",
            "Epoch 30, Validation Loss: 2.4608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_sentence(model, sentence, input_word2idx, output_idx2word, max_length=50):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Preprocessing\n",
        "        sentence = preprocess_text(sentence)\n",
        "        # Konversi ke indeks\n",
        "        inputs = torch.tensor([sentence_to_indices(sentence, input_word2idx)], dtype=torch.long).to(device)\n",
        "\n",
        "        hidden, cell = model.encoder(inputs)\n",
        "        x = torch.tensor([output_word2idx['<SOS>']], dtype=torch.long).to(device)\n",
        "        outputs = []\n",
        "        for _ in range(max_length):\n",
        "            output, hidden, cell = model.decoder(x, hidden, cell)\n",
        "            best_guess = output.argmax(1)\n",
        "            if best_guess.item() == output_word2idx['<EOS>']:\n",
        "                break\n",
        "            outputs.append(best_guess.item())\n",
        "            x = best_guess\n",
        "    translated_sentence = ' '.join([output_idx2word[idx] for idx in outputs])\n",
        "    return translated_sentence"
      ],
      "metadata": {
        "id": "IxouvkXyBhtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sentiment scores\n",
        "sentiment_scores = {}\n",
        "\n",
        "# Load positive sentiment words\n",
        "with open('sentiment/tsv/positive.tsv', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, score = line.strip().split('\\t')\n",
        "        sentiment_scores[word] = int(score)\n",
        "\n",
        "# Load negative sentiment words\n",
        "with open('sentiment/tsv/negative.tsv', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        word, score = line.strip().split('\\t')\n",
        "        sentiment_scores[word] = int(score)\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    words = text.split()\n",
        "    score = 0\n",
        "    for word in words:\n",
        "        score += sentiment_scores.get(word, 0)\n",
        "    return score\n",
        "\n",
        "def adjust_response_by_sentiment(response, sentiment_score):\n",
        "    if sentiment_score < 0:\n",
        "        response = \"Maaf mendengarnya. \" + response\n",
        "    elif sentiment_score > 0:\n",
        "        response = \"Senang mendengarnya! \" + response\n",
        "    return response\n",
        "\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.type) for ent in doc.ents]\n",
        "    return entities\n",
        "\n",
        "def generate_template_response(entities):\n",
        "    if entities:\n",
        "        for entity, ent_type in entities:\n",
        "            if ent_type == 'PER':\n",
        "                return f\"Halo {entity}, apa kabar?\"\n",
        "            elif ent_type == 'ORG':\n",
        "                return f\"Apa kabar dengan {entity}?\"\n",
        "    return None"
      ],
      "metadata": {
        "id": "wNFLs8NyBq9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Analisis sentimen\n",
        "    sentiment_score = analyze_sentiment(user_input)\n",
        "\n",
        "    # Ekstrak entitas\n",
        "    entities = extract_entities(user_input)\n",
        "\n",
        "    # Coba generate response berbasis template\n",
        "    response = generate_template_response(entities)\n",
        "    if response is None:\n",
        "        # Jika tidak ada entitas, gunakan model\n",
        "        response = translate_sentence(model, user_input, input_word2idx, output_idx2word)\n",
        "\n",
        "    # Sesuaikan respon berdasarkan sentimen\n",
        "    response = adjust_response_by_sentiment(response, sentiment_score)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "hIpqSx5-BtK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Pre-trained Model\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained('facebook/mbart-large-50-many-to-many-mmt')\n",
        "model_transformer = MBartForConditionalGeneration.from_pretrained('facebook/mbart-large-50-many-to-many-mmt').to(device)\n",
        "tokenizer.src_lang = \"id_ID\"\n",
        "tokenizer.tgt_lang = \"id_ID\"\n",
        "\n",
        "def generate_transformer_response(input_text):\n",
        "    # Preprocessing\n",
        "    input_text = preprocess_text(input_text)\n",
        "    # Tokenisasi\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    # Generate\n",
        "    output_ids = model_transformer.generate(input_ids, num_beams=5, max_length=50, early_stopping=True)\n",
        "    # Decode\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Modifikasi fungsi chatbot_response untuk menggunakan Transformer\n",
        "def chatbot_response_transformer(user_input):\n",
        "    # Analisis sentimen\n",
        "    sentiment_score = analyze_sentiment(user_input)\n",
        "\n",
        "    # Ekstrak entitas\n",
        "    entities = extract_entities(user_input)\n",
        "\n",
        "    # Coba generate response berbasis template\n",
        "    response = generate_template_response(entities)\n",
        "    if response is None:\n",
        "        # Jika tidak ada entitas, gunakan model Transformer\n",
        "        response = generate_transformer_response(user_input)\n",
        "\n",
        "    # Sesuaikan respon berdasarkan sentimen\n",
        "    response = adjust_response_by_sentiment(response, sentiment_score)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "JvFOhC0OBvKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat loop\n",
        "print(\"Selamat datang di Chatbot! Ketik 'exit' untuk keluar.\")\n",
        "while True:\n",
        "    user_input = input(\"Anda: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Chatbot: Sampai jumpa!\")\n",
        "        break\n",
        "    bot_response = chatbot_response(user_input)\n",
        "    print(f\"Chatbot: {bot_response}\")"
      ],
      "metadata": {
        "id": "n4MGj9WpBxt-",
        "outputId": "e246505b-6e09-43f7-f88e-90809ce231c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selamat datang di Chatbot! Ketik 'exit' untuk keluar.\n",
            "Anda: halo\n",
            "Chatbot: Good luck.\n",
            "Anda: kamu siapa\n",
            "Chatbot: In fact, it's not as if we're going to be able to get rid of it.\n",
            "Anda: siapa kamu\n",
            "Chatbot: In fact, it's not as if we're going to be able to get rid of it.\n",
            "Anda: halo\n",
            "Chatbot: Good luck.\n",
            "Anda: siapa kamu\n",
            "Chatbot: In fact, it's not as if we're going to be able to get rid of it.\n",
            "Anda: aku bermimpi\n",
            "Chatbot: Dreams.\n",
            "Anda: iya\n",
            "Chatbot: Yeah.\n",
            "Anda: sakit \n",
            "Chatbot: Maaf mendengarnya. pain.\n",
            "Anda: apa kamu suka bermain bola?\n",
            "Chatbot: Senang mendengarnya! Do you like to play football?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BklzuDTRB6NL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSi3Jiw92BXSwaMy6klIo2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a12607554eea41c490e1f5ced90e155f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c19e77b5e384bcf8a356bcabaf85674",
              "IPY_MODEL_14f373296b0f4b1e95d0377ab1cc4c93",
              "IPY_MODEL_44ec5659fe6248c0ac0f9159432d28ba"
            ],
            "layout": "IPY_MODEL_4acc871b566743ca9512ecd93477d610"
          }
        },
        "4c19e77b5e384bcf8a356bcabaf85674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6914613b3764e37a122455c257c7421",
            "placeholder": "​",
            "style": "IPY_MODEL_0281dcac88584cc9ad10fa8ab6a5c96c",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "14f373296b0f4b1e95d0377ab1cc4c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f15e9899cc4ca390baefae14bfc0b0",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ce05ff926da4626926bb2c6e89bcccd",
            "value": 48453
          }
        },
        "44ec5659fe6248c0ac0f9159432d28ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1af3c38d93f445c83c0bf926d4f2914",
            "placeholder": "​",
            "style": "IPY_MODEL_4c38740fe29f48399abdb052e34a817f",
            "value": " 392k/? [00:00&lt;00:00, 8.77MB/s]"
          }
        },
        "4acc871b566743ca9512ecd93477d610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6914613b3764e37a122455c257c7421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0281dcac88584cc9ad10fa8ab6a5c96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41f15e9899cc4ca390baefae14bfc0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ce05ff926da4626926bb2c6e89bcccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1af3c38d93f445c83c0bf926d4f2914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c38740fe29f48399abdb052e34a817f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4829483efe8b49488a904e632f5ac32b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6198ca1a06a54d009f4bacc7e4be598d",
              "IPY_MODEL_02f2e974c93e40f680d3221295edd13b",
              "IPY_MODEL_c4cfdd33300948c082fa677a7db63c56"
            ],
            "layout": "IPY_MODEL_35cf77d5b258472a9769013580e6349a"
          }
        },
        "6198ca1a06a54d009f4bacc7e4be598d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8615ebee419435c8699e3e1f53773e2",
            "placeholder": "​",
            "style": "IPY_MODEL_8d33f766d4834d66a0dd7f54119f1271",
            "value": "Downloading https://huggingface.co/stanfordnlp/stanza-id/resolve/v1.9.0/models/default.zip: 100%"
          }
        },
        "02f2e974c93e40f680d3221295edd13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57a3c3fb203046cca87d9053e12baef1",
            "max": 395483754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2c52ccdfb504ed996f893fa39242d5e",
            "value": 395483754
          }
        },
        "c4cfdd33300948c082fa677a7db63c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb056953e944d3c9ae14584cb2800f6",
            "placeholder": "​",
            "style": "IPY_MODEL_4579de5039e647eb989ca5ebdcee1760",
            "value": " 395M/395M [00:07&lt;00:00, 18.2MB/s]"
          }
        },
        "35cf77d5b258472a9769013580e6349a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8615ebee419435c8699e3e1f53773e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d33f766d4834d66a0dd7f54119f1271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57a3c3fb203046cca87d9053e12baef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c52ccdfb504ed996f893fa39242d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccb056953e944d3c9ae14584cb2800f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4579de5039e647eb989ca5ebdcee1760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a5b58f5734f4e099dd7b25b2ba44912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_452bd189e9c04d52b0893360e72858d0",
              "IPY_MODEL_708110d4718c4fcf91be57fc77e4919b",
              "IPY_MODEL_299657f864d44ebba3046218a0a12c06"
            ],
            "layout": "IPY_MODEL_54d00c244f0842abacf252f3b8f8c94c"
          }
        },
        "452bd189e9c04d52b0893360e72858d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f8c9fa4efe24700951d5d00b7d9856b",
            "placeholder": "​",
            "style": "IPY_MODEL_1aa896e594754a89b117cce9734ed80c",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: "
          }
        },
        "708110d4718c4fcf91be57fc77e4919b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b758b259db694a1db717777ed8d2e89a",
            "max": 48453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b60d4a4e16a4c4da241dce0a6677f24",
            "value": 48453
          }
        },
        "299657f864d44ebba3046218a0a12c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc24971afadf43b89e3d573d5f2701ca",
            "placeholder": "​",
            "style": "IPY_MODEL_8b2af3c4034a46689f689edff5d551f0",
            "value": " 392k/? [00:00&lt;00:00, 22.6MB/s]"
          }
        },
        "54d00c244f0842abacf252f3b8f8c94c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f8c9fa4efe24700951d5d00b7d9856b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aa896e594754a89b117cce9734ed80c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b758b259db694a1db717777ed8d2e89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b60d4a4e16a4c4da241dce0a6677f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc24971afadf43b89e3d573d5f2701ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2af3c4034a46689f689edff5d551f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}